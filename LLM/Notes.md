# Models

### Paid Models
- GPT from OpenAI
- Claude from Anthropic
- Gemini from Google
- Command R from Cohere
- Perplexity

<img width="949" alt="image" src="https://github.com/user-attachments/assets/18acac2a-6539-440b-a532-34bc5043ee6c" />

### OpenSource Models
- Llama from Meta
- Mixtral from Mistral
- Qwen from Alibaba Cloud
- Gemma from Googl
- Phi from Microsoft

  <img width="947" alt="image" src="https://github.com/user-attachments/assets/f039fee4-ca32-473f-93ee-5ed16472609d" />

## RAG
- https://github.com/langchain-ai/rag-from-scratch

### Overview of LLM
- Large language models (LLMs) are defined by the number of parameters, also called weights, which control their output.
- Traditional machine learning models typically have between 20 and 200 parameters, whereas LLMs have millions to trillions of parameters.
- LLM Models are trained and operated by tokens - https://platform.openai.com/tokenizer 
